
Канал: https://t.me/metrics_ru

Всё сказанное ниже, сказано с целью уберечь инженера от неправильного или плохого выбора. 
Каждая из описанных систем обсуждалась на канале неоднократно и тут сделана попытка сделать выжимку частых вопросов. 

Про Zabbix
===========

В церкви запрещено использовать сравнительные эпитеты к заббиксу. По нашему опыту это рождает холивары в которых нет не правых, но и истины тоже немного. 

Если очень хочется поговорить про заббикс - https://t.me/ZabbixPro

Q: Почему Zabbix говно? Я вот пользуюсь и мне норм

A: По множеству причин:
  * Реляционные базы данных не подходят для time-series. 
  Когда даже плохие системы тянут сотни тысяч точек в секунду, заббиксу становится уже плохо.
  * Zabbix отвратительно масштабируется.
  * Он не вписывается в современные концепции мониторинга (многомерные метрики, точнее теги, мониторинг по метрикам в первую очередь).
  * Он не подходит для работы с короткоживущими метриками, например из докера.
  * См. его bugtracker и список Feature Request'ов. Все важное из него давно реализуется другими системами мониторинга, но не заббиксом.
  * Как вишенка на торте - особо отвратительный интерфейс в духе "привет 90ые"


Q: Что использовать вместо InfluxDB и Zabbix?

A: Graphite + Moira/Bosun/баш скрипты или Prometheus

Про InfluxDB
============

Q: Я хочу взять InfluxDB чтобы запилить X

A: Не надо.

Q: Но он же такой хороший, вот про него сколько сказано крутого

A: Это маркетинг. Не ведитесь.

Q: А какие у него проблемы? Вот я в него начал отправлять 20 метрик в секунду и он отлично работает!

A: Вот краткий и неполный список проблем на момент версии 1.4 (применимо и к более младшим):

  * Стабильность. Периодически падает и теряет данные.
  * Скорость. Заявленное в маркетинговых бумажках касается не постоянного рейта, а спайков. "Show tag keys from all" на средней базе может положить все.
  * Потребление ресурсов . Сожрать 256ГБ RAM, закусить 320GB свопа и все равно упасть по OOMу - легко (в момент 6и часового запуска).
  * Платная кластеризация.
  * Частые breaking changes. За 3 года сменили 5+ движков, периодически выкатывают фичи непонятно зачем сделанные, например сделали ifql.
  * Безалаберность при подготовке релизов. Например как они ломали поддержку Прометея в телеграфе 1.3.2 (замена символов не попадающих под [a-z], https://github.com/influxdata/telegraf/issues/2937). В целом недостаточное тестирование релизов.
  * Не самосогласованные утилиты экспорта и импорта из базы - если вы что-то экспортировали через cli, то импортировать обратно файлик не прокатит. restore из backup полностью заменяет всю метаинформацию о базах. Селективности и merge не завезли.


Про Graphite
============

Q: Раз Graphite такой клевый, почему его все не используют?

A: Потому что он тоже говно. А все потому что:
  * Он очень любит I/O, делает много мелких IOPS при работе с диском.
  * Он не очень приспособлен под мониторинг короткоживущих сущностностей (нет адекватной поддержки тегов), нет метаданных.
  * Тяжел в плане администрирования (single-server решение с кластеризацией где-то сбоку и набором странных скриптов для управления всем)
  * Оригинальный написан на питоне, поэтому еще и адски медленный (пользуйтесь по возможности https://github.com/go-graphite и https://github.com/lomik/go-carbon или https://github.com/lomik/carbon-clickhouse)
  * Слишком многое есть в альтернативной реализации, включая несколько видов совместимых хранилищ, но из которых почти все работает не очень хорошо.


Про Prometheus
==============


Q: Ладно, возьму пром.
A: Но и пром говно
Q: Да как так?
A: Ну вот вкратце:

1. Очень большие проблемы с хранением данных в долгосрочном периоде. Какие-то варианты есть, но они все в итоге заставляют или использовать пром исключительно как сборщик + оповещалку, или строить дашборды по два раза. remote read протокол полное днище, потому что подразумевает вычисление всех функций на стороне самого прома;
2. Алертинг в начинающей стадии. Нужно городить костыли или колхозы для чего-то, что можно просто найти в другой экосистеме. То есть вопрос даже не в продвинутых фичах типа "Сделай что-то по алерту", вопрос в подавлениях, условиях роутинга, разделение на команды и прочей приятной мелочи. Значительно проще тупо отдавать все стороннему решению (например, Alerta, icinga и т.д.);
3. Очень, то есть ОЧЕНЬ чувствителен к корректному использованию тегов. Решили запихнуть url path в тег? Ну, вас ждет неприятный сюрприз, последствие которого будут еще очень долго вам аукатся;
4. Pull модель. Даже не так, особенная pull модель, которая не обнуляет данные после их получения. Помните пункт 3? Ну так вот, айда перезапускать все сервисы подряд;
5. Офигенный подход к агрегированию метрик для нескольких процессов в клиентских либах (для веб приложений написанных на python, js, php или тех, кто предпочитает 12factor) приводит к тому, что даже после перезапуска сервисы могут подхватить из какого-то внешнего источника (redis, файлы) все эти метрики и начать свистопляску заново;
6. Очень германская модель данных. Вам может показатся, что она какая-то кривая, но, обычно, вам расскажут, что вы неправы. Без вариантов;
7. Нет никаких шансов на внятные расширения внутри самого языка. Новые фичи так же внедряются исключительно для цели служения нордической модели данных. Хотите что-то классное? Вас ждет remote read/write протоколы и много страдания, как всегда;
8. Хотите HA? Ну тогда просто ставьте два независимых прома и пусть они собирают данные независимо. Как жить, если между ними будут расхождения? Ну, открывайте томик мат. статистики;
9. Вы хотите защитить метрики от условного похищения, поставить basic auth или даже tls security? Ну .... Не хотите. Пока;
10. Нет вебморды для редактирования, нет никакого разделения по ролям внутри - все ентерпрайз фичи делаются только через отдельные инстанты. Это к тому, что если вам нужно разграничивать видимость метрик внутри прома, то ... вам не нужно;
11. У вас нет никакого инструмента управлениями конфигураций (в духе Ansible), на серверах не бороздят просторы консулы, куберы и прочая штука? Ну .... вперед писать длинные портянки файлов вручную, так как идеология прома подразумевает по отдельному экспортеру на сервис;

Ах да, из всяких мелочей:
* Очень важно помнить, что вы работаете с временным рядами. И потеря части точек - это не проблема
* Пром не попадает в ваш use case? У вас даже нет шансов его докрутить до какой-то кондиции
* Stateless алертинг. Перезапустили пром? Ну вот все ваши активные алерты и тю-тю. Для алертов с большими for это обычно очень приятно. Говорят с поздних версиях исправлено
* Что бы работать с blackbox expoter нужно убить в себе программиста.
* Вам может показатся, что в какой-то момент вам будет нужен pushgateway. На самом деле, это еще одна ловушка для пытливых умов, которые ломают головы, зачем нужно это чудо после существования textcollector в node_exporter и statsd_expoter.



Про Cacti
=========

Q: Почему Cacti говно?

A: Краткий список собственно почему:

  * rrd под капотом 
  * как следствие первого пункта, невозможность самому, внятно, управлять аггрегацией метрик
  * нулевая масштабируемость
  * pooler модель сбора метрик
  * околонулевая возможность автоматизации (т.е. она есть, но чтобы ее настроить до вменяемого состояния нужно потратить уйму времени)
  * прожорливость до iops, даже со всякими boost плагинами
  * нет вменяемых дашбордов
  * заточен в основном под сетевые девайсы - мониторить им сервера клауды и прочие контейнеры мазохизм

Q: Почему тогда ее еще не закопали?

A: Потому что все еще торт! Ну а на самом деле все-таки неплохо мониторит сетевые девайсы, многое для сети есть из коробки, логика отображения устройств в виде дерева хорошо ложиться в голову менеджеров и прочего руководящего состава и они ее любят.
